{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anis16/-c/blob/main/NAFNet_stereo_Image_Denoising.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JI3vDyk_Idn"
      },
      "source": [
        "# NAFNet Online Demo on Image Denoising"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdfuLYPRiAry"
      },
      "source": [
        "## Git clone [NAFNet](https://github.com/megvii-research/NAFNet) repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn1wnYiQHLCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a65601-c736-4049-b95d-a36cdd1498fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'NAFNet' already exists and is not an empty directory.\n",
            "/content/NAFNet\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/megvii-research/NAFNet\n",
        "%cd NAFNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZPB5RCmh9pg"
      },
      "source": [
        "## Set up the enviroment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-MVdSsJHnPj"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!python3 setup.py develop --no_cuda_ext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUZSEIxYiywI"
      },
      "source": [
        "## Download pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiElLLM2HS4D"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=14Fht1QQJ2gMlk4N1ERCRuElg8JfjrWWR', \"./experiments/pretrained_models/\", quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbo3cwHoGb96"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1TIdQhPtBrZb2wrBdAp9l8NHINLeExOwb -O ./experiments/pretrained_models/\n",
        "!gdown https://drive.google.com/drive/folders/1zWedm3Q6_6pxTql881DR6xe-v9SPUe70?usp=sharing --folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fPOD1Jdzry6"
      },
      "source": [
        "## Download Demo Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLzZcXvBzw2w"
      },
      "outputs": [],
      "source": [
        "gdown.download('https://drive.google.com/uc?id=1uKwZUgeGfBYLlPKllSuzgGUItlzb40hm', \"demo_input/\", quiet=False)\n",
        "gdown.download('https://drive.google.com/uc?id=1ov6UqpIA6GjjJT5SdGeUAJECxka14nGf', \"demo_input/\", quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c49IzmJlq6at"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def ssim(img1, img2):\n",
        "    C1 = (0.01 * 255)**2\n",
        "    C2 = (0.03 * 255)**2\n",
        "\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
        "    window = np.outer(kernel, kernel.transpose())\n",
        "\n",
        "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
        "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
        "    mu1_sq = mu1**2\n",
        "    mu2_sq = mu2**2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
        "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
        "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
        "                                                            (sigma1_sq + sigma2_sq + C2))\n",
        "    return ssim_map.mean()\n",
        "\n",
        "\n",
        "def calculate_ssim(img1, img2):\n",
        "    '''calculate SSIM\n",
        "    the same outputs as MATLAB's\n",
        "    img1, img2: [0, 255]\n",
        "    '''\n",
        "    if not img1.shape == img2.shape:\n",
        "        raise ValueError('Input images must have the same dimensions.')\n",
        "    if img1.ndim == 2:\n",
        "        return ssim(img1, img2)\n",
        "    elif img1.ndim == 3:\n",
        "        if img1.shape[2] == 3:\n",
        "            ssims = []\n",
        "            for i in range(3):\n",
        "                ssims.append(ssim(img1, img2))\n",
        "            return np.array(ssims).mean()\n",
        "        elif img1.shape[2] == 1:\n",
        "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
        "    else:\n",
        "        raise ValueError('Wrong input image dimensions.')\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def calculate_psnr(img1, img2):\n",
        "    # img1 and img2 have range [0, 255]\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    mse = np.mean((img1 - img2)**2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    return 20 * math.log10(255.0 / math.sqrt(mse))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ZU5PSHjjo6"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RKjUG_IIWb2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from basicsr.models import create_model\n",
        "from basicsr.utils import img2tensor as _img2tensor, tensor2img, imwrite\n",
        "from basicsr.utils.options import parse\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "def img2tensor(img, bgr2rgb=False, float32=True):\n",
        "    img = img.astype(np.float32) / 255.\n",
        "    return _img2tensor(img, bgr2rgb=bgr2rgb, float32=float32)\n",
        "\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1) \n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('NAFNet output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "\n",
        "def single_image_inference(model, img, save_path):\n",
        "      model.feed_data(data={'lq': img.unsqueeze(dim=0)})\n",
        "\n",
        "      if model.opt['val'].get('grids', False):\n",
        "          model.grids()\n",
        "\n",
        "      model.test()\n",
        "\n",
        "      if model.opt['val'].get('grids', False):\n",
        "          model.grids_inverse()\n",
        "\n",
        "      visuals = model.get_current_visuals()\n",
        "      sr_img = tensor2img([visuals['result']])\n",
        "      \n",
        "    \n",
        "      imwrite(sr_img, save_path)\n",
        "def displaystereo(LR_l, LR_r, SR_l, SR_r):\n",
        "  h,w = SR_l.shape[:2]\n",
        "  LR_l = cv2.resize(LR_l, (w,h), interpolation=cv2.INTER_CUBIC)\n",
        "  LR_r = cv2.resize(LR_r, (w,h), interpolation=cv2.INTER_CUBIC)\n",
        "  fig = plt.figure(figsize=(w//40, h//40))\n",
        "  ax1 = fig.add_subplot(2, 2, 1) \n",
        "  plt.title('Input image (Left)', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(2, 2, 2)\n",
        "  plt.title('NAFSSR output (Left)', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(LR_l)\n",
        "  ax2.imshow(SR_l)\n",
        "\n",
        "  ax3 = fig.add_subplot(2, 2, 3) \n",
        "  plt.title('Input image (Right)', fontsize=16)\n",
        "  ax3.axis('off')\n",
        "  ax4 = fig.add_subplot(2, 2, 4)\n",
        "  plt.title('NAFSSR output (Right)', fontsize=16)\n",
        "  ax4.axis('off')\n",
        "  ax3.imshow(LR_r)\n",
        "  ax4.imshow(SR_r)\n",
        "\n",
        "  plt.subplots_adjust(wspace=0.04, hspace=0.04)\n",
        "\n",
        "def stereo_image_inference(model, img_l, img_r, save_path):\n",
        "      img = torch.cat([img_l, img_r], dim=0)\n",
        "      model.feed_data(data={'lq': img.unsqueeze(dim=0)})\n",
        "\n",
        "      if model.opt['val'].get('grids', False):\n",
        "          model.grids()\n",
        "\n",
        "      model.test()\n",
        "\n",
        "      if model.opt['val'].get('grids', False):\n",
        "          model.grids_inverse()\n",
        "\n",
        "      visuals = model.get_current_visuals()\n",
        "      img_L = visuals['result'][:,:3]\n",
        "      img_R = visuals['result'][:,3:]\n",
        "      img_L, img_R = tensor2img([img_L, img_R])\n",
        "      img_L = cv2.resize(img_L,(400,400), interpolation = cv2.INTER_AREA)\n",
        "      img_R = cv2.resize(img_R,(400,400), interpolation = cv2.INTER_AREA)\n",
        "      imwrite(img_L, save_path.format('L'))\n",
        "      imwrite(img_R, save_path.format('R'))\n",
        "def denoising(img_l,img_r):\n",
        "  save_path='/content/denoised/image1{}.png'\n",
        "  #output_path='/content/Noisy/image1{}.png'\n",
        "  img_l = cv2.resize(img_l,(400,400), interpolation = cv2.INTER_AREA)\n",
        "  img_r = cv2.resize(img_r,(400,400), interpolation = cv2.INTER_AREA)\n",
        "  img_l= img2tensor(img_l)\n",
        "  img_r= img2tensor(img_r)\n",
        "  #stereo_image_inference(NAFSSR, img_l, img_r, output_path)\n",
        "  #img_input_L = imread(output_path.format('L'))\n",
        "  #inp_L= img2tensor(img_input_L)\n",
        "  single_image_inference(NAFNet, img_l, save_path.format('L'))\n",
        "  #img_input_R = imread(output_path.format('R'))\n",
        "  #inp_R= img2tensor(img_input_R)\n",
        "  single_image_inference(NAFNet, img_r, save_path.format('R'))\n",
        "  return save_path.format('L'),save_path.format('R')\n",
        "  \n",
        "  \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPZyTTRMjmet"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EveBvGLIZ2AM"
      },
      "outputs": [],
      "source": [
        "opt_path1 = 'options/test/SIDD/NAFNet-width64.yml'\n",
        "opt1 = parse(opt_path1, is_train=False)\n",
        "opt1['dist'] = False\n",
        "NAFNet = create_model(opt1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2m94wXdGvc6"
      },
      "outputs": [],
      "source": [
        "opt_path = 'options/test/NAFSSR/NAFSSR-L_4x.yml'\n",
        "opt = parse(opt_path, is_train=False)\n",
        "opt['dist'] = False\n",
        "NAFSSR = create_model(opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jco3tXqTZe6T"
      },
      "outputs": [],
      "source": [
        "def noisy(image,sigma):\n",
        "      row,col,ch= image.shape\n",
        "      mean = 0\n",
        "      image=image/255\n",
        "      gauss = np.random.normal(mean,sigma,(row,col,ch))/100\n",
        "      noisy=np.zeros(image.shape)\n",
        "      for i in range(row):\n",
        "        for j in range(col):\n",
        "           noisy[i,j,:]=image[i,j,:]+gauss[i,j,:]\n",
        "           \n",
        "           if noisy[i,j,0]>1:\n",
        "             noisy[i,j,0]=1\n",
        "           if noisy[i,j,1]>1:\n",
        "             noisy[i,j,1]=1  \n",
        "           if noisy[i,j,2]>1:\n",
        "             noisy[i,j,2]=1  \n",
        "           if noisy[i,j,0]<0:\n",
        "             noisy[i,j,0]=0\n",
        "           if noisy[i,j,1]<0:\n",
        "             noisy[i,j,1]=0  \n",
        "           if noisy[i,j,2]<0:\n",
        "             noisy[i,j,2]=0    \n",
        "      return noisy*255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add gaussian Noise to clean image\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_nbZGEEZK-H_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGr0MyHPiY36"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "img1L=cv2.imread('/content/079_L.png')\n",
        "img1R=cv2.imread('/content/079_R.png')\n",
        "imglN=noisy(img1L,35)\n",
        "\n",
        "imgrN=noisy(img1R,35)\n",
        "#imglN=cv2.cvtColor(imglN,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#imgrN=cv2.cvtColor(imgrN,cv2.COLOR_BGR2RGB)\n",
        "cv2.imwrite('/content/079_{}_noisy_35.png'.format('L'),imglN)\n",
        "cv2.imwrite('/content/079_{}_noisy_35.png'.format('R'),imgrN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvqgrtpceIlv"
      },
      "source": [
        "# Inference and Show results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "4FRQ4Bg8L-4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tyWI0qpd89Z"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "title = \"Stereo image denoising \"\n",
        "description = \"Stereo image denoising with NAFSSR + denoising NAFNet\"\n",
        "article = \"<p style='text-align: center'><a href='https://arxiv.org/abs/2204.04676' target='_blank'>Simple Baselines for Image Restoration</a> | <a href='https://arxiv.org/abs/2204.08714' target='_blank'>NAFSSR: Stereo Image Super-Resolution Using NAFNet</a>  | <a href='https://github.com/megvii-research/NAFNet' target='_blank'> Github Repo</a></p>\"\n",
        "\n",
        "\n",
        "            \n",
        "iface = gr.Interface(\n",
        "    denoising, \n",
        "    [gr.inputs.Image(type=\"numpy\", label=\"Input Left\"),\n",
        "     gr.inputs.Image(type=\"numpy\", label=\"Input Right\")\n",
        "    ], \n",
        "    [gr.outputs.Image(type=\"file\", label=\"Output Left\"),\n",
        "    gr.outputs.Image(type=\"file\", label=\"Output Right\")],\n",
        "    title=title,\n",
        "    description=description,\n",
        "    article=article,\n",
        "    enable_queue=True,\n",
        "    \n",
        "    )\n",
        "iface.launch(debug=True,enable_queue=True)\n",
        "      "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": " NAFNet stereo Image Denoising",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}